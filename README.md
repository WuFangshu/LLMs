<h1 align="center">
Xmodel_VLM: A Simple Baseline for Multimodal Vision Language Model
</h1>

<h5 align="center">

[![hf_space](https://img.shields.io/badge/ü§ó-Xiaoduo%20HuggingFace-blue.svg)](https://huggingface.co/XiaoduoAILab/Xmodel_VLM)
[![arXiv](https://img.shields.io/badge/Arxiv-2405.09215-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2405.09215) 
[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](https://github.com/tatsu-lab/stanford_alpaca/blob/main/LICENSE)
[![github](https://img.shields.io/badge/-Github-black?logo=github)](https://github.com/XiaoduoAILab/XmodelVLM.git)[![github](https://img.shields.io/github/stars/XiaoduoAILab/XmodelVLM.svg?style=social)](https://github.com/XiaoduoAILab/XmodelVLM.git)  


</h5>





## üõ†Ô∏è Install

1. Clone this repository and navigate to MobileVLM folder
   ```bash
   git clone [https://github.com/](https://github.com/XiaoduoAILab/XmodelVLM.git)
   cd xmodelvlm
   ```

2. Install Package
    ```Shell
    conda create -n xmodelvlm python=3.10 -y
    conda activate xmodelvlm
    pip install --upgrade pip
    pip install -r requirements.txt
    ```

## üóùÔ∏è Quick Start

#### Example for Xmodel_VLM model inference
```python


```

## ü™ú Step-by-step Tutorial

### Xmodel_VLM

#### 1Ô∏è‚É£ Prepare Xmodel_VLM checkpoints

#### 2Ô∏è‚É£ Prepare data

#### 3Ô∏è‚É£ Run everything with one click!


## ü§ù Acknowledgments


## ‚úèÔ∏è Reference


